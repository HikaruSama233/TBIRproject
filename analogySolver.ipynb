{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1: Run several analogy solving models with several different representations on the benchmarking analogy dataset and report your findings. \n",
    "\n",
    "Focus on the following questions:\n",
    "\n",
    "1. Is the choice of the analogy model important? Which representations work better with which analogy models?\n",
    "2. Is dimensionality of the representation important when using GloVe vectors?\n",
    "3. What is the computational complexity of the analogy models given the pre-trained vectors?\n",
    "4. What are the typical errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import models, matutils\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model from disk\n",
    "word2vec_model = models.word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative3000.bin', binary = True)\n",
    "# method for computing cosine_similarity (since we normalize the vectors) cos_sim(v1, v2) = np.dot(v1, v2)\n",
    "\n",
    "# pre-processing: change all vectors of words into unit vectors, not able to do it. any ideas?\n",
    "vec2compare = map(lambda x : matutils.unitvec(word2vec_model[x]), word2vec_model.vocab)\n",
    "\n",
    "def findAnalogy(a, b, c): \n",
    "    \"\"\"a to b is c to d. a, b, c, d are all words. d = argmax(cos(d', c-a+b))\"\"\"\n",
    "    mixedNormVec = None\n",
    "    for word in b + c:\n",
    "        if not word in word2vec_model.vocab:\n",
    "            raise KeyError(\"word '%s' not in vocabulary\" % word)\n",
    "    if a in word2vec_model.vocab:\n",
    "        mixedNormVec = matutils.unitvec(word2vec_model[b] + word2vec_model[c] - word2vec_model[a])\n",
    "    else:\n",
    "        raise KeyError(\"word '%s' not in vocabulary\" % a)\n",
    "    if not mixedNormVec:\n",
    "        raise ValueError(\"sorry for any inconvenient...\")\n",
    "    sims = np.dot(vec2compare, mixedNormVec)\n",
    "    best = matutils.argsort(sims, topn = 5, reverse=True)\n",
    "    # ignore words from the input\n",
    "    result = [(word2vec_model.index2word[sim], float(sims[sim])) for sim in best if sim not in a + b + c]\n",
    "    return result[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
