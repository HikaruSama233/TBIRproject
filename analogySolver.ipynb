{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Task1: Run several analogy solving models with several different representations on the benchmarking analogy dataset and report your findings._ \n",
    "\n",
    "Focus on the following questions:\n",
    "\n",
    "1. Is the choice of the analogy model important? Which representations work better with which analogy models?\n",
    "    \n",
    "    Yes. The choice of the analogy model will affect not only computation complexity but also recall. \n",
    "    \n",
    "    For word2vec model, multiplication model works better than additional model.\n",
    "    \n",
    "    For GloVe model, when dimensions are lower than 300, additional model is better than multiplication model. When dimension equals to 300,\n",
    "    multiplication model is better.\n",
    "    \n",
    "    I didn't implement the direction model.\n",
    "    \n",
    "2. Is dimensionality of the representation important when using GloVe vectors?\n",
    "    \n",
    "    Yes. When dimensions are relatively high, the performance (recalll) of the same analogy model increases because it can keep more features\n",
    "    or hidden information of words.\n",
    "    \n",
    "3. What is the computational complexity of the analogy models given the pre-trained vectors?\n",
    "\n",
    "    I introduced restrict_vocab to reduce the computation complexity. We only need to search analogy word from restric_vocab words \n",
    "    instead of all words in the dictionary. \n",
    "    \n",
    "    Set the number of questions is N, the number of restricted vocabulary is n (equals to restrict_vocab), the dimension of each word vector \n",
    "    is (1, d), the number of all words in dictionary is n_all.\n",
    "    Assume the sorting function doesn't need any time and space.\n",
    "    \n",
    "    For addition model, the time complexity is O(N\\*d\\*n), the space complexity is O(n_all\\*d)\n",
    "    \n",
    "    For multiplication model, the time complexity is O(N\\*d\\*n\\*3), the space complexity is O(n_all\\*d) . The computation of this model is \n",
    "    longer than addition model because it needs calculate inner product for 3 times. For each question, after doing the inner product, \n",
    "    there will be 3 word vectors with dimension (1, n). The numerical mutiplication of these 3 vectors need extra time O(N\\*n) which is \n",
    "    much shorter than O(N\\*d\\*n\\*3) so we can ignore it.\n",
    "    \n",
    "    The extra space for computation is about O(1, n) which is much smaller than O(n_all\\*d) so we can also ignore it. \n",
    "    O(n_all\\*d) is the space for storing the pre-trained model. \n",
    "\n",
    "4. What are the typical errors?\n",
    "    \n",
    "    One error is from the testing set. It says London is capital of England but actually it is UK or Britain. So there are about 200 false negative is about that. The country name has many representations. They have the same meaning but they don't have exactly the same string. This is the reason that cause false negative. \n",
    "    \n",
    "    Another error is the given word is not in the vocabulary (capital letter matters). So it doesn't have a vector to present itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import models, matutils, utils\n",
    "import numpy as np\n",
    "import smart_open\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "from six import iteritems\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "# Get logging information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glove2word2vec(glove_filename):\n",
    "    \"\"\"\n",
    "    Convert glove file to word2vec format\n",
    "    The only difference between word2vec format and glove is\n",
    "    word2vec provides number of lines and dimension of word vectors\n",
    "    in first line\n",
    "    This is a short cut for given 4 glove file:\n",
    "        \"glove.6B.50d.txt\", \"glove.6B.100d.txt\", \"glove.6B.200d.txt\", \"glove.6B.300d.txt\"\n",
    "    Other format of glove filename needs other modification of getFirstLineInfo    \n",
    "    \"\"\"\n",
    "    def getFirstLineInfo(glove_filename):\n",
    "        \"\"\"\n",
    "        Calculate the number of lines and dimensions of word vector\n",
    "        \"\"\"\n",
    "        num_lines = sum(1 for line in smart_open.smart_open(glove_filename))\n",
    "        # the file name of glove file contains number of dimensions so we can extract that from file name\n",
    "        dims = glove_filename.split('.')[2].split('d')[0]\n",
    "        return num_lines, dims\n",
    "    \n",
    "    def addFirstLine(glove_filename, word2vec_filename, first_line_info):\n",
    "        \"\"\"\n",
    "        Add information of number of lines and dimensions into the first line\n",
    "        \"\"\"\n",
    "        with smart_open.smart_open(glove_filename, 'rb') as infile:\n",
    "            with smart_open.smart_open(word2vec_filename, 'wb') as outfile:\n",
    "                outfile.write(str(first_line_info) + '\\n')\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "        return word2vec_filename\n",
    "    \n",
    "    word2vec_filename = glove_filename[:-3] + \"word2vec.txt\"\n",
    "    if os.path.isfile(word2vec_filename):\n",
    "        model = models.word2vec.Word2Vec.load_word2vec_format(word2vec_filename)\n",
    "    else:\n",
    "        num_lines, dims = getFirstLineInfo(glove_filename)\n",
    "        first_line = \"{} {}\".format(num_lines, dims)\n",
    "        model_file = addFirstLine(glove_filename, word2vec_filename, first_line)\n",
    "        model = models.word2vec.Word2Vec.load_word2vec_format(model_file)\n",
    "    \n",
    "    # normalize all word vectors\n",
    "    model.init_sims(replace = True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findAnalogy_model1(a, b, c, model, restrict_vocab = None): \n",
    "    \"\"\"\n",
    "    addition model\n",
    "    a to b is c to d. a, b, c, d are all words. \n",
    "    d = argmax(cos(d', c-a+b)). \n",
    "    \n",
    "    bonus:\n",
    "        If you want to find the most corrected word of a given word, you can use\n",
    "        findAnalogy_model1(\"empty\", \"empty\", \"given_word\", model)\n",
    "        yes. I know you find out the first two \"empty\" can be replaced by any word but these two must be exactly the same word.\n",
    "    \"\"\"\n",
    "    mixedNormVec = None\n",
    "    all_words = set()\n",
    "    for word in [a, b, c]:\n",
    "        if not word in model.vocab:\n",
    "            raise KeyError(\"word '%s' not in vocabulary\" % word)\n",
    "        else:\n",
    "            all_words.add(model.vocab[word].index)\n",
    "    # normalize the result of b + c - a. prepare for computing cosine similarity\n",
    "    mixedNormVec = matutils.unitvec(model[b] + model[c] - model[a]).astype(np.float32)\n",
    "    \n",
    "    limited = model.syn0norm if restrict_vocab is None else model.syn0norm[:restrict_vocab]\n",
    "    # calculate the cosine similarity between all words (d') and c-a+b\n",
    "    sims = np.dot(limited, mixedNormVec)\n",
    "    # find 15 best result which is the highest similarity score\n",
    "    # it is possible that finding the same word as a or b or c \n",
    "    # so we need to give some space for other possible words\n",
    "    best = matutils.argsort(sims, topn = 15, reverse=True)\n",
    "    # ignore words from the input and words with special symbols\n",
    "    result = [(model.index2word[sim], float(sims[sim])) for sim in best if (sim not in all_words) and ((\"_\" not in model.index2word[sim]) or \\\n",
    "                                                                                                       ((\"\\\\\") not in model.index2word))]\n",
    "    return result[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cr(arr):\n",
    "    \"\"\"\n",
    "    cr for Convert Range\n",
    "    arr is a numpy array\n",
    "    \"\"\"\n",
    "    return ((arr + 1.0) / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findAnalogy_model2(a, b, c, model, restrict_vocab = None):\n",
    "    \"\"\"\n",
    "    multiplication model\n",
    "    a to b is c to d. d = argmax(cos(d',c)*cos(d',b)/(cos(d',a)+e))\n",
    "    e = 0.001 to avoid division by zero\n",
    "    \"\"\"\n",
    "    all_words = set()\n",
    "    for word in [a, b, c]:\n",
    "        if not word in model.vocab:\n",
    "            raise KeyError(\"word '%s' not in vocabulary\" % word)\n",
    "        else:\n",
    "            all_words.add(model.vocab[word].index)\n",
    "\n",
    "    limited = model.syn0norm if restrict_vocab is None else model.syn0norm[:restrict_vocab]\n",
    "    sims = (cr(np.dot(limited, model.syn0norm[model.vocab[c].index])) * cr(np.dot(limited, model.syn0norm[model.vocab[b].index]))) / \\\n",
    "        (cr(np.dot(limited, model.syn0norm[model.vocab[a].index])) + 0.001)\n",
    "    best = matutils.argsort(sims, topn = 15, reverse=True)\n",
    "    # ignore words from the input\n",
    "    result = [(model.index2word[sim], float(sims[sim])) for sim in best if (sim not in all_words) and ((\"_\" not in model.index2word[sim]) or \\\n",
    "                                                                                                       ((\"\\\\\") not in model.index2word))]\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findAnalogyPerLine(line, r_model, a_model, currentCount, restrict_vocab = None, caps = False):\n",
    "    \"\"\"\n",
    "    For each question, I have a, b, c, expected. I need to guess d from a, b, c and compare that with expected\n",
    "    currentCount is a list contains two elements, first one is number of current correct answer\n",
    "    the second one is the number of all questions we tested so far\n",
    "    \"\"\"\n",
    "    if line[0] == ':':\n",
    "        return currentCount\n",
    "    else:\n",
    "        if caps:\n",
    "            a, b, c, expected = line.split()\n",
    "        else:\n",
    "            a, b, c, expected = [word.lower() for word in line.split()]\n",
    "        currentCount[1] += 1\n",
    "        if a_model == 1:\n",
    "            d = findAnalogy_model1(a, b, c, r_model, restrict_vocab = restrict_vocab)\n",
    "        elif a_model == 2:\n",
    "            d = findAnalogy_model2(a, b, c, r_model, restrict_vocab = restrict_vocab)\n",
    "        else:\n",
    "            raise ValueError(\"invalid analogy model\")\n",
    "        if d[0] == expected:\n",
    "            currentCount[0] += 1\n",
    "    return currentCount        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recallOfAnalogyModel(questions, r_model, a_model, restrict_vocab = 30000, caps = False):\n",
    "    \"\"\"\n",
    "    questions are file path for the test file. In this case, 'questions-words.txt'\n",
    "    r_model is representation model of word vector (word2vec, GloVe)\n",
    "    a_model is analogy model (1, 2). 1 stands for findAnalogy_model1, 2 stands for findAnalogy_model2\n",
    "    restrict the number of words to be compared to increase the speed. \n",
    "    caps determines if we need to keep all capital letters. True for keeping, False for transforming into lower case\n",
    "    \"\"\"\n",
    "    # currentCount is a list contains two elements, first one is number of current correct answer\n",
    "    currentCount = [0, 0]\n",
    "    random.seed(0) # set a random seed to reproduce the random numbers\n",
    "    # randomly select about 1/20 of questions to limit the computation time\n",
    "    rand_lines =[random.randint(i*20, (i + 1) * 20) for i in range(19558 // 20)]\n",
    "    # the words with lower count will not be considered as an option for answer of analogy question. They will be kicked out of ok_vocab\n",
    "    ok_vocab = dict(sorted(iteritems(r_model.vocab), key=lambda item: -item[1].count)[:restrict_vocab])\n",
    "    with open(questions, 'r') as ifile:\n",
    "        for line_no, line in enumerate(utils.smart_open(questions)):\n",
    "            if line_no in rand_lines:\n",
    "                if line[0] != \":\":\n",
    "                    if caps:\n",
    "                        a, b, c, expected = line.split()\n",
    "                    else:\n",
    "                        # transform all letters into lower case letters\n",
    "                        a, b, c, expected = [word.lower() for word in line.split()]\n",
    "                    if a not in ok_vocab or b not in ok_vocab or c not in ok_vocab or expected not in ok_vocab:\n",
    "                        logger.info(\"skipping line #%i with OOV words: %s\" % (line_no, line.strip()))\n",
    "                        continue\n",
    "                    else:\n",
    "                        findAnalogyPerLine(line, r_model, a_model, currentCount, restrict_vocab = restrict_vocab, caps = caps)\n",
    "                        \n",
    "                if currentCount[1]  % 200 == 0:\n",
    "                    loginfo = \"correct pair:\" + str(currentCount[0]) + \", total pair:\" + str(currentCount[1])\n",
    "                    logger.info(loginfo)\n",
    "    \n",
    "    recall = float(currentCount[0]) / float(currentCount[1])\n",
    "    return float('%.4f'% recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "INFO:gensim.models.word2vec:loaded (3000000L, 300L) matrix from GoogleNews-vectors-negative300.bin\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained representation model. Whether load those model at the same time depends on the space of your RAM\n",
    "\n",
    "# Load pre-trained word2vec model from disk\n",
    "word2vec_model = models.word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True)\n",
    "\n",
    "# word2vec_model.vocab: 3000000  words for word2vec_model.\n",
    "# each word are represented as a vector with 300 terms\n",
    "# word2vec_model.syn0: matrix for the model\n",
    "# word2vec_model.syn0.shape: check the shape of this matrix\n",
    "# Normalize all vectors in this model. \n",
    "# So we can use dot product to calculate cosine similarity which is more efficient\n",
    "word2vec_model.init_sims(replace = True)\n",
    "# The normalized vectors are stored in model.syn0 and model.syn0norm. These are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:skipping line #965 with OOV words: Baghdad Iraq Funafuti Tuvalu\n",
      "INFO:root:skipping line #1041 with OOV words: Bamako Mali Funafuti Tuvalu\n",
      "INFO:root:skipping line #1231 with OOV words: Belgrade Serbia Funafuti Tuvalu\n",
      "INFO:root:skipping line #1535 with OOV words: Budapest Hungary Funafuti Tuvalu\n",
      "INFO:root:skipping line #2075 with OOV words: Funafuti Tuvalu Jakarta Indonesia\n",
      "INFO:root:skipping line #2082 with OOV words: Funafuti Tuvalu Kingston Jamaica\n",
      "INFO:root:skipping line #2104 with OOV words: Funafuti Tuvalu Niamey Niger\n",
      "INFO:root:skipping line #2373 with OOV words: Islamabad Pakistan Nuuk Greenland\n",
      "INFO:root:skipping line #2639 with OOV words: Kigali Rwanda Nuuk Greenland\n",
      "INFO:root:skipping line #2753 with OOV words: Lilongwe Malawi Nuuk Greenland\n",
      "INFO:root:skipping line #3209 with OOV words: Minsk Belarus Nuuk Greenland\n",
      "INFO:root:skipping line #3440 with OOV words: Nairobi Kenya Paramaribo Suriname\n",
      "INFO:root:skipping line #3633 with OOV words: Nuuk Greenland Quito Ecuador\n",
      "INFO:root:skipping line #3655 with OOV words: Nuuk Greenland Valletta Malta\n",
      "INFO:root:skipping line #3668 with OOV words: Oslo Norway Paramaribo Suriname\n",
      "INFO:root:skipping line #3767 with OOV words: Paramaribo Suriname Tunis Tunisia\n",
      "INFO:root:skipping line #4186 with OOV words: Stockholm Sweden Vaduz Liechtenstein\n",
      "INFO:root:correct pair:151, total pair:200\n",
      "INFO:root:skipping line #4682 with OOV words: Vaduz Liechtenstein Vienna Austria\n",
      "INFO:root:skipping line #4717 with OOV words: Vaduz Liechtenstein Cairo Egypt\n",
      "INFO:root:skipping line #5079 with OOV words: Angola kwanza Malaysia ringgit\n",
      "INFO:root:skipping line #5194 with OOV words: Bulgaria lev Romania leu\n",
      "INFO:root:skipping line #5218 with OOV words: Cambodia riel Malaysia ringgit\n",
      "INFO:root:skipping line #5233 with OOV words: Cambodia riel Brazil real\n",
      "INFO:root:skipping line #5415 with OOV words: Iran rial Nigeria naira\n",
      "INFO:root:skipping line #5427 with OOV words: Iran rial Armenia dram\n",
      "INFO:root:skipping line #5453 with OOV words: Japan yen Angola kwanza\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:skipping line #5625 with OOV words: Mexico peso Cambodia riel\n",
      "INFO:root:skipping line #5701 with OOV words: Romania leu USA dollar\n",
      "INFO:root:skipping line #5782 with OOV words: Sweden krona Romania leu\n",
      "INFO:root:correct pair:292, total pair:400\n",
      "INFO:root:skipping line #10312 with OOV words: informative uninformative ethical unethical\n",
      "INFO:root:skipping line #10343 with OOV words: informed uninformed informative uninformative\n",
      "INFO:root:correct pair:425, total pair:600\n",
      "INFO:root:skipping line #14350 with OOV words: Belarus Belorussian Brazil Brazilian\n",
      "INFO:root:skipping line #14374 with OOV words: Belarus Belorussian Netherlands Dutch\n",
      "INFO:root:skipping line #14384 with OOV words: Belarus Belorussian Thailand Thai\n",
      "INFO:root:skipping line #14580 with OOV words: China Chinese Belarus Belorussian\n",
      "INFO:root:skipping line #14998 with OOV words: Ireland Irish Belarus Belorussian\n",
      "INFO:root:correct pair:592, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " recall of word2vec & addition model: 0.7441\n"
     ]
    }
   ],
   "source": [
    "print \"recall of word2vec & addition model:\", \\\n",
    "recallOfAnalogyModel('questions-words.txt', word2vec_model, 1, restrict_vocab = 200000, caps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:skipping line #965 with OOV words: Baghdad Iraq Funafuti Tuvalu\n",
      "INFO:root:skipping line #1041 with OOV words: Bamako Mali Funafuti Tuvalu\n",
      "INFO:root:skipping line #1231 with OOV words: Belgrade Serbia Funafuti Tuvalu\n",
      "INFO:root:skipping line #1535 with OOV words: Budapest Hungary Funafuti Tuvalu\n",
      "INFO:root:skipping line #2075 with OOV words: Funafuti Tuvalu Jakarta Indonesia\n",
      "INFO:root:skipping line #2082 with OOV words: Funafuti Tuvalu Kingston Jamaica\n",
      "INFO:root:skipping line #2104 with OOV words: Funafuti Tuvalu Niamey Niger\n",
      "INFO:root:skipping line #2373 with OOV words: Islamabad Pakistan Nuuk Greenland\n",
      "INFO:root:skipping line #2639 with OOV words: Kigali Rwanda Nuuk Greenland\n",
      "INFO:root:skipping line #2753 with OOV words: Lilongwe Malawi Nuuk Greenland\n",
      "INFO:root:skipping line #3209 with OOV words: Minsk Belarus Nuuk Greenland\n",
      "INFO:root:skipping line #3440 with OOV words: Nairobi Kenya Paramaribo Suriname\n",
      "INFO:root:skipping line #3633 with OOV words: Nuuk Greenland Quito Ecuador\n",
      "INFO:root:skipping line #3655 with OOV words: Nuuk Greenland Valletta Malta\n",
      "INFO:root:skipping line #3668 with OOV words: Oslo Norway Paramaribo Suriname\n",
      "INFO:root:skipping line #3767 with OOV words: Paramaribo Suriname Tunis Tunisia\n",
      "INFO:root:skipping line #4186 with OOV words: Stockholm Sweden Vaduz Liechtenstein\n",
      "INFO:root:correct pair:156, total pair:200\n",
      "INFO:root:skipping line #4682 with OOV words: Vaduz Liechtenstein Vienna Austria\n",
      "INFO:root:skipping line #4717 with OOV words: Vaduz Liechtenstein Cairo Egypt\n",
      "INFO:root:skipping line #5079 with OOV words: Angola kwanza Malaysia ringgit\n",
      "INFO:root:skipping line #5194 with OOV words: Bulgaria lev Romania leu\n",
      "INFO:root:skipping line #5218 with OOV words: Cambodia riel Malaysia ringgit\n",
      "INFO:root:skipping line #5233 with OOV words: Cambodia riel Brazil real\n",
      "INFO:root:skipping line #5415 with OOV words: Iran rial Nigeria naira\n",
      "INFO:root:skipping line #5427 with OOV words: Iran rial Armenia dram\n",
      "INFO:root:skipping line #5453 with OOV words: Japan yen Angola kwanza\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:skipping line #5625 with OOV words: Mexico peso Cambodia riel\n",
      "INFO:root:skipping line #5701 with OOV words: Romania leu USA dollar\n",
      "INFO:root:skipping line #5782 with OOV words: Sweden krona Romania leu\n",
      "INFO:root:correct pair:297, total pair:400\n",
      "INFO:root:skipping line #10312 with OOV words: informative uninformative ethical unethical\n",
      "INFO:root:skipping line #10343 with OOV words: informed uninformed informative uninformative\n",
      "INFO:root:correct pair:431, total pair:600\n",
      "INFO:root:skipping line #14350 with OOV words: Belarus Belorussian Brazil Brazilian\n",
      "INFO:root:skipping line #14374 with OOV words: Belarus Belorussian Netherlands Dutch\n",
      "INFO:root:skipping line #14384 with OOV words: Belarus Belorussian Thailand Thai\n",
      "INFO:root:skipping line #14580 with OOV words: China Chinese Belarus Belorussian\n",
      "INFO:root:skipping line #14998 with OOV words: Ireland Irish Belarus Belorussian\n",
      "INFO:root:correct pair:601, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of word2vec & mutiplication model: 0.7633\n"
     ]
    }
   ],
   "source": [
    "print \"recall of word2vec & mutiplication model:\", \\\n",
    "recallOfAnalogyModel('questions-words.txt', word2vec_model, 2, restrict_vocab = 200000, caps = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Release this part of memory for the rest of models\n",
    "del word2vec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from glove.6B.50d.word2vec.txt\n",
      "WARNING:gensim.models.word2vec:consider setting layer size to a multiple of 4 for greater performance\n",
      "INFO:gensim.models.word2vec:loaded (400000L, 50L) matrix from glove.6B.50d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained glove model from dist\n",
    "glove50d_model = glove2word2vec('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:122, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:177, total pair:400\n",
      "INFO:root:correct pair:238, total pair:600\n",
      "INFO:root:correct pair:352, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove50d & addition model: 0.4425\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove50d & addition model:\", recallOfAnalogyModel('questions-words.txt', glove50d_model, 1, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:98, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:131, total pair:400\n",
      "INFO:root:correct pair:182, total pair:600\n",
      "INFO:root:correct pair:276, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove50d & multiplication model: 0.3501\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove50d & multiplication model:\", recallOfAnalogyModel('questions-words.txt', glove50d_model, 2, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del glove50d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000L, 100L) matrix from glove.6B.100d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained glove model from dist\n",
    "glove100d_model = glove2word2vec('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:167, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:262, total pair:400\n",
      "INFO:root:correct pair:362, total pair:600\n",
      "INFO:root:correct pair:511, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove100d & addition model: 0.6335\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove100d & addition model:\", recallOfAnalogyModel('questions-words.txt', glove100d_model, 1, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:156, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:243, total pair:400\n",
      "INFO:root:correct pair:336, total pair:600\n",
      "INFO:root:correct pair:473, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove100d & multiplication model: 0.5945\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove100d & multiplication model:\", recallOfAnalogyModel('questions-words.txt', glove100d_model, 2, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del glove100d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000L, 200L) matrix from glove.6B.200d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained glove model from dist\n",
    "glove200d_model = glove2word2vec('glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:181, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:291, total pair:400\n",
      "INFO:root:correct pair:405, total pair:600\n",
      "INFO:root:correct pair:564, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove200d & addition model: 0.6951\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove200d & addition model:\", recallOfAnalogyModel('questions-words.txt', glove200d_model, 1, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:177, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:282, total pair:400\n",
      "INFO:root:correct pair:393, total pair:600\n",
      "INFO:root:correct pair:553, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove200d & multiplication model: 0.6858\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove200d & multiplication model:\", recallOfAnalogyModel('questions-words.txt', glove200d_model, 2, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del glove200d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from glove.6B.300d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:loaded (400000L, 300L) matrix from glove.6B.300d.word2vec.txt\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained glove model from dist\n",
    "glove300d_model = glove2word2vec('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:183, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:300, total pair:400\n",
      "INFO:root:correct pair:421, total pair:600\n",
      "INFO:root:correct pair:584, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove300d & addition model: 0.7136\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove300d & addition model:\", recallOfAnalogyModel('questions-words.txt', glove300d_model, 1, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:correct pair:183, total pair:200\n",
      "INFO:root:skipping line #5571 with OOV words: Macedonia denar Canada dollar\n",
      "INFO:root:skipping line #5610 with OOV words: Malaysia ringgit Macedonia denar\n",
      "INFO:root:correct pair:303, total pair:400\n",
      "INFO:root:correct pair:428, total pair:600\n",
      "INFO:root:correct pair:594, total pair:800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of glove300d & multiplication model: 0.732\n"
     ]
    }
   ],
   "source": [
    "print \"recall of glove300d & multiplication model:\", recallOfAnalogyModel('questions-words.txt', glove300d_model, 2, restrict_vocab = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del glove300d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
