{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline \n",
    "# make plots show in ipython notebook\n",
    "\n",
    "from gensim import models, matutils, utils\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import itertools\n",
    "import string\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# Get logging information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "INFO:gensim.models.word2vec:loaded (3000000L, 300L) matrix from GoogleNews-vectors-negative300.bin\n",
      "INFO:gensim.models.word2vec:precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained representation model. Whether load those model at the same time depends on the space of your RAM\n",
    "\n",
    "# Load pre-trained word2vec model from disk\n",
    "word2vec_model = models.word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True) \n",
    "#word2vec_model = models.word2vec.Word2Vec.load_word2vec_format('glove.6B.100d.word2vec.txt', binary = False)\n",
    "\n",
    "# word2vec_model.vocab: 3000000  words for word2vec_model.\n",
    "# each word are represented as a vector with 300 terms\n",
    "# word2vec_model.syn0: matrix for the model\n",
    "# word2vec_model.syn0.shape: check the shape of this matrix\n",
    "# Normalize all vectors in this model. \n",
    "# So we can use dot product to calculate cosine similarity which is more efficient\n",
    "word2vec_model.init_sims(replace = True)\n",
    "# The normalized vectors are stored in model.syn0 and model.syn0norm. These are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:target file loaded. 17784 documents.\n",
      "INFO:root:query file loaded. 1000 queries.\n"
     ]
    }
   ],
   "source": [
    "# Load two files\n",
    "target_file = pd.read_table(\"target_collection\", compression = None, header = 0, sep = '\\t')\n",
    "logger.info((\"target file loaded. \" + str(np.shape(target_file)[0]) + \" documents.\"))\n",
    "query_file = pd.read_table(\"queries_val\", compression = None, header = 0, sep = '\\t')\n",
    "logger.info((\"query file loaded. \" + str(np.shape(query_file)[0]) + \" queries.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>img_id</th>\n",
       "      <th>txt_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> EiS5L2wmSbJq8Y3u</td>\n",
       "      <td> A picture of a man standing next to a horse on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> P5xKs0Q1QB8vbgVH</td>\n",
       "      <td>                       A man is holding up a fish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2</td>\n",
       "      <td> u5EXhe28CW4XySoT</td>\n",
       "      <td> There is man motioning with his hands in front...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3</td>\n",
       "      <td> cpmk_ry7TG3lTvlX</td>\n",
       "      <td> A man wearing a green coat holding something i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 4</td>\n",
       "      <td> IawGgdRJoTmZSYEs</td>\n",
       "      <td>        Chairs in a circle in front of some books.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id            img_id  \\\n",
       "0        0  EiS5L2wmSbJq8Y3u   \n",
       "1        1  P5xKs0Q1QB8vbgVH   \n",
       "2        2  u5EXhe28CW4XySoT   \n",
       "3        3  cpmk_ry7TG3lTvlX   \n",
       "4        4  IawGgdRJoTmZSYEs   \n",
       "\n",
       "                                         txt_caption  \n",
       "0  A picture of a man standing next to a horse on...  \n",
       "1                        A man is holding up a fish.  \n",
       "2  There is man motioning with his hands in front...  \n",
       "3  A man wearing a green coat holding something i...  \n",
       "4         Chairs in a circle in front of some books.  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"split text into words, remove punctuations, remove stop words\"\"\"\n",
    "    tokens0 = nltk.word_tokenize(text)\n",
    "    tokens1 = [t for t in tokens0 if t not in [',', '.', '``', '\"', \"'\", \"''\"]]\n",
    "    tokens = [t for t in tokens1 if t not in stopwords.words('english')]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildDic():\n",
    "    \"\"\"build dictionary for all targets and save word vectors for each target as matrix\"\"\"\n",
    "    for row in target_file.itertuples():\n",
    "        tokens = tokenize(row[3])\n",
    "        target_dic[row[1]] = [word2vec_model[tok] for tok in tokens if tok in word2vec_model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Program Files\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "buildDic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortestDistance(mat1, mat2):\n",
    "    \"\"\"calculate distance for moving all words in query matrix (mat1) to target matrix (mat2)\"\"\"\n",
    "    dist_mat = euclidean_distances(mat1, mat2) # euclidean distances for every pair of words\n",
    "    shortestDist = np.mean([np.min(word_dis) for word_dis in dist_mat]) # average of shortest distance for moving one word to another word\n",
    "    return shortestDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def querySimilarity(query):\n",
    "    \"\"\"rank all targets for each query\"\"\"\n",
    "    tokens = tokenize(query)\n",
    "    query_mat = [word2vec_model[t] for t in tokens if t in word2vec_model.vocab] # transform query to query matrix\n",
    "    sims = [shortestDistance(query_mat, target_dic[k]) for k in target_dic.keys()]\n",
    "    # sort by similarity score (distance) increasingly\n",
    "    sims = np.array(sims)\n",
    "    best0 = np.argsort(sims)[:1000]\n",
    "    best = [best0, sims[best0]]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAveragePrecision(query_img_id, best, cutoff):\n",
    "    \"\"\"get AP for a query at recall@cutoff\"\"\"\n",
    "    tp_series = np.where(np.asarray([target_file['img_id'][x] for x in best[:cutoff]]) == query_img_id)[0]\n",
    "    tp_tpfp = [(i_no + 1.0)/(i + 1.0) for i_no, i in enumerate(tp_series)]# precision = (tp/(tp+fp))\n",
    "    tpfn = len(np.where(target_file['img_id'] == query_img_id)[0]) #tp+fn\n",
    "    averPrec = sum(tp_tpfp)/tpfn\n",
    "    return averPrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def precAndRec(query_img_id, best):\n",
    "    \"\"\"compute precision-recall curve for a query\"\"\"\n",
    "    tp_series = np.where(np.array([target_file['img_id'][x] for x in best]) == query_img_id)[0]\n",
    "    # tp_accu = np.array([0] * len(tp_series))\n",
    "    tp_tpfp = [(i_no + 1.0)/(i + 1.0) for i_no, i in enumerate(tp_series)]# precision = (tp/(tp+fp))\n",
    "    tpfn = len(np.where(target_file['img_id'] == query_img_id)[0]) #tp+fnï¼Œ denominator for recall\n",
    "    tmp = 0\n",
    "    i = 0\n",
    "    precRecall_arr = [0.0] * 11\n",
    "    # computation of precision based on 11 standard recall levels      \n",
    "    for tmp in range(len(tp_tpfp)):\n",
    "        while (i/10.0) <= ((tmp + 1.0) / tpfn):\n",
    "            precRecall_arr[i] = tp_tpfp[tmp]\n",
    "            i += 1\n",
    "    return np.array(precRecall_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanResult(modelName, graph = False):\n",
    "    \"\"\"calculate average of AP and precision-recall for all queries\"\"\"\n",
    "    sum_averagePrecision = []\n",
    "    sum_precision = np.array([0.0] * 11)\n",
    "    # loop over all queries\n",
    "    for row in query_file.itertuples():\n",
    "        query, query_img_id = row[3], row[2]\n",
    "        best = querySimilarity(query)\n",
    "        sum_averagePrecision.append(getAveragePrecision(query_img_id, best[0], 1000))\n",
    "        if row[0] % 100 == 0:\n",
    "            logger.info(row[0])\n",
    "        if graph:\n",
    "            prec = precAndRec(query_img_id, best[0])\n",
    "            sum_precision += prec\n",
    "    \n",
    "    meanAP = np.mean(sum_averagePrecision)\n",
    "    print(\"Mean Average Precision of \" + modelName + \" is: \", str(meanAP))\n",
    "    if graph:\n",
    "        pylab.plot(np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), sum_precision / 1000)\n",
    "        pylab.xlabel('recall')\n",
    "        pylab.ylabel('precision')\n",
    "        pylab.title(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:0\n",
      "INFO:root:100\n",
      "INFO:root:200\n",
      "INFO:root:300\n",
      "INFO:root:400\n",
      "INFO:root:500\n",
      "INFO:root:600\n",
      "INFO:root:700\n",
      "INFO:root:800\n",
      "INFO:root:900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision of Word Mover Distance Model is:  0.22629868106\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHVWd//H3h7AIKIIiKpuIAoI/gxsIuEVEjCvjghBk\n",
       "ExdcGNcZFxwxI6MMz6CioIiIsigiqChGRBANIPsWcIQgi0BCYGSXTQnk8/vjVJPbne707aTr1l0+\n",
       "r+fpJ3Wr6lZ9u26nvvecU+cc2SYiImLICk0HEBER3SWJISIihkliiIiIYZIYIiJimCSGiIgYJokh\n",
       "IiKGSWKI2kmaKen4puOok6QNJd0vSU3H0k0kLZK0cRv7TZM0rxMxxfiSGAaQpM9JOm3EuuvGWPeu\n",
       "STjlmJ1lqhvCIkk/H7F+y2r9Hybh/MtF0t6SHqtu/PdLulHS9yVtMrSP7VtsP8njdAyqjnVu/VFP\n",
       "jKTZ1fWeOmL9KdX6VzUVW3ReEsNgOhvYbujbraRnAisCL5S0Qsu65wDnTOTAkqYsQzx3ANtIekrL\n",
       "ur2Av7CUpFIHSSuOsek8208C1gB2AB4GLpP0/I4FVy8D1wJ7Dq2Q9FRgW+BvTQUVzUhiGEyXAisB\n",
       "L6xevxL4A+VG3LruBtu3S1pX0qmS7qpKEe8bOlBVTfRTScdLug/YS9KzJZ0t6e+SzgDWHieeR4Bf\n",
       "ALtWx5wCvAv4EfB41Yyk7SRdIuleSRdL2rZav4ukS1oPKOkTkn5ZLa8i6RBJN0u6XdIRkp5QbZsm\n",
       "ab6kT0u6DTh6jBgF4OJG2x+hJNiZ1XE2qr5ZDyXWvSXdUF2DGyXtJul5wHeAbauSx93Vvm+SdIWk\n",
       "+yTdIumLLb/H0HH3rOK/Q9L+LdtXkLS/pOurc10qaf1q2/MknVl9bnMl7TzO53ACsEtLddgM4OfA\n",
       "wpbzrSLpUEm3Vj9fl7Ryy/Z/l7Sguqb7jPhMxvwcorskMQwg248AFwGvrla9CjgX+GO1PLTu7Gr5\n",
       "ROAW4JnAO4GvSHpNyyHfCpxs+8mUm8sJwCXAU4EDKd/+x/vmfzyLv62+HvhfYMHQxqo08WvgUOAp\n",
       "wNeAX0taC/gVsJmk57YcbzdKYgH4b+C5wJbVv+sBB7Ts+3RgLWBDYN9x4mz1c0oCHUbS6sA3gOm2\n",
       "16B8655je251/AuqaqehEtIDwO7V9XsT8CFJO4047MuBTYHXAgdI2qxa/ylKQn1Dda73AA9VMZwJ\n",
       "/BB4WrXPtyVtvpTfZwFwNeX6A+wBHDdin88DW1Ou5ZbV8n9Uv/f0Kp4dqlh3GPHe8T6H6Ba28zOA\n",
       "P8AXgZ9Xy3Mo1Uavb1l3JeXGsAHwKLB6y3u/AvygWp4JzG7ZtiHlG+aqLet+BBw/RhzTgHnV8l8o\n",
       "N5QTKd9W3wv8odq2B3DhiPeeD+xVLR8PfKFa3gT4O/AEyjf9B4CNW963LXBjy/n/Cay8lGu1N3Du\n",
       "KOunA49UyxsBiyhftlYH7gHe3nodlnasEfscCnxtxHHXbdl+EfCuavla4C2jHGMX4JwR644EDhjj\n",
       "nH+orve7KYn9ecC11bZ5wKuq5espCW/ofTsCf62Wvw98pWXbJlXsG7f5Ocxr+v9FfspPSgyD6xzg\n",
       "FdU37qfZvgG4gNL2sBbw/GqfdYG7bT/Y8t5bKN/2hsxvWV4XuMf2wy3rbm4zpuOBf6XcJE6hpRqp\n",
       "Ou4tI/a/uVoP5WY2o1reDTjF9j8o35ZXo7QH3CPpHuA3DK/eusOlFDVR6wF3j1xZXatdgA8CCyTN\n",
       "avmGvwRJL5P0B0l/k3QvpVTx1BG73d6y/BDwxGp5feCGUQ77LOBlQ79z9XvvRikdjcWUUtD2wEdY\n",
       "srQA5Xq3fp63sPgzeCYlibRuG9LO5xBdIolhcF0IPBl4P3AegO2/U6oTPgAssH1z9fopkp7Y8t4N\n",
       "GZ4MWquJbgPWkrRay7pn0V4j8g+BDwG/rm7qrW6tjtPqWdV6gN8BT5O0JaXa5IRq/Z2UhuItbK9V\n",
       "/azpUu0yWvwT8TbGaJy3fYbtHYFnAHOBo5ZyrhMobSzr216T0g7R7v/NeZRqmZFuAc5u+Z3Xcqm+\n",
       "+sjSDlYl9N9QktpojxgvoJRihmzI4s/gtup167Yh7XwO0SWSGAZUdQO4FPgkw29uf6zWnV3tN49S\n",
       "ZXNQ1Xg4FdiHchMf7bg3V8f9T0krSXoF8OY2Y/orpW3j86Ns/g2wqaQZklaUtAulumNW9d6FwMnA\n",
       "IZT2gjOr9YsoN+VDJT0NQNJ6knZsJ6aRJE2pGtcPq2L9z1H2WUfSTlU9/0LgQeCxavP/AetLWqnl\n",
       "LU+klLIekbQ15Zt9u8nqe8CBkp6rYmrVHjOLcr12rz6HlSRtVTWAj2d/4NW2R5bQAH4M/IektSWt\n",
       "TWkjGPpbOAnYW9Lm1ReDxxvRJ/tziHolMQy2sylF/D+2rDuXUrxvTRYzKN8SF1CqGg6w/ftqm1ny\n",
       "JrYb8DJKNcsBwLHjxPH4+22fb/v2lvWu1t9FSTCfonz7/DfgzbZbq3JOoDTOnlzdiIZ8hlI3fqHK\n",
       "k1NnUtoyljj/UuLbVtL9wH2U+vgnAlvZ/vMox1kB+ATlm/RdlAbqD1XbzgL+DNwuaegx0A8DX5L0\n",
       "d+ALwE9GOf9Yvka5IZ9RxXYU8ATbD1Dq/3et4rgNOAhYeYzjLD6ZfZvt88fY/F+UxH9V9XNptQ7b\n",
       "p1PaR35PaS86a0Tsy/s5RIfIru+zqJ5SOBSYAnzP9sGj7DMN+Drl8ck7bU+rLaCIiBhXbYlB5Vn0\n",
       "aymPrN1KeXxxhu1rWvZZk1K//Xrb8yWtbfvOWgKKiIi21FmVtDVwve2bqvrfE4GRz2bvBvzM9nyA\n",
       "JIWIiObVmRjWY/ija/MZ/ogjlOecn1I9qneppD1qjCciItow1rgwk6GdOqqVgBdTGgxXAy6QdKHt\n",
       "62qMKyIilqLOxHArpdfskA0Y/uw7lBLFndWjkw9LOofSXX5YYpCUpxUiIpaB7QkPBV9nYrgU2ETS\n",
       "RpTHHHdhcc/UIb8EDq8aqlehPOL4tdEOtiy/XD+SNNP2zKbj6Aa5FovlWiyWa7HYsn6pri0x2H5U\n",
       "0n7AbymPqx5t+xpJ+1bbj7Q9V9LplOehFwFH2b66rpgiImJ8dZYYsP0bSo/V1nVHjnh9CKW3akRE\n",
       "dIH0fO49s5sOoIvMbjqALjK76QC6yOymA+h1tfZ8niySnDaGiIiJWdZ7Z0oMERExTBJDREQMk8QQ\n",
       "ERHD9ExikPiixDpNxxER0e96JjFQxlm6VuK7Eu1MNhIREcugZxKDzQeAzSi9qM+WmCXxGok8rRQR\n",
       "MYl68nFViVWBPShTUD4EfBU4yWZhQyFGRHSdZX1ctScTw+L1rAC8kZIgNgG+CRxlc2+HQ4yI6DoD\n",
       "2Y/BZpHNLJvtKZMAbQncKPF1iY2ajS4iojf1dGJoZXO5ze6U5LAQuEziJImXNRxaRERP6emqpKW/\n",
       "hycB7wU+TpkH4qvAqTaP1RBiRETXGcg2hvbey4rA24FPAU8Fvg4cY/PgJIYYEdF1khjGPQYCtqMk\n",
       "iFcCRwGH2dw2CSFGRHSdgWx8nggb25xn83ZgW2AN4GqJYySmNhxeRETXGJjE0Mrmepv9gOcAfwFO\n",
       "lzhD4vXpMBcRg25gqpKWfnxWAXalVDOtQJl3+kc2/6zrnBERdUsbw6ScBwE7UBLElsC3gCNs7qr7\n",
       "3BERky1tDJOgaoc402Y68DpgY+B6iW9LPLfh8CIiOiKJYQw2/2uzD7A5cBdwYUZ1jYhBkKqktmPg\n",
       "Q8A+wHYZrC8iekGqkur3HeBOYP+mA4mIqFNKDBOKg3WBK4A321zSdDwREUuTEkMH2CwAPgocL7Fa\n",
       "0/FERNQhJYZlIHECcIfNx5qOJSJiLOnH0EESawFXAe+x+V3T8UREjCZVSR1kcw9lSO/vS6zZdDwR\n",
       "EZOp1sQgabqkuZKuk/SZUbZPk3SfpCuqn/+oM57JZHMGcCpweNOxRERMphXrOrCkKZSb5g7ArcAl\n",
       "kk61fc2IXc+2/da64qjZp4ErJHa2ObnpYCIiJkOdJYatgett32R7IXAiZV7mkbqm7WCibB4C9gAO\n",
       "k3hm0/FEREyGOhPDesC8ltfzq3WtDGwn6UpJp0naosZ4amFzMfBd4OgM2R0R/aDOxNDO406XAxvY\n",
       "3hI4DPhFjfHU6UBgHeD9TQcSEbG8amtjoLQrbNDyegNKqeFxtu9vWf6NpG9Leortu0ceTNLMlpez\n",
       "bc+e3HCXnc1CiT2AcyTOsrmh6ZgiYvBImgZMW+7j1NWPQdKKwLXAa4EFwMXAjNbGZ0lPB/5m25K2\n",
       "Bk6yvdEox+qqfgxjkfg4sDPwKpvHmo4nIgZb1/VjsP0osB/wW+Bq4Ce2r5G0r6R9q93eCfxJ0hzg\n",
       "UMosar3sm8A/KE8rRUT0pPR8nmQSGwKXAa+zmdN0PBExuLquxDCobG6hTA16vMQTmo4nImKikhjq\n",
       "cTzwF8rTShERPSVVSTWRWJsy0N6uNuc0HU9EDJ5UJXUZmzuBDwDHSqzRdDwREe1KiaFmEkcBK9i8\n",
       "t+lYImKwpMTQvT4JTJPo1YECI2LApMTQARKvAE4CtrS5o+l4ImIwpMTQxWz+SHlS6bsZaC8iul0S\n",
       "Q+ccAGwM7NV0IBERS5OqpA6SmAqcBbzU5uam44mI/paqpB5gcxXwP8AxUq59RHSn3Jw676uU4c4/\n",
       "3nQgERGjSVVSAyQ2Bi4Cptn8uel4IqI/pSqph9jcCHyOMtDeyk3HExHRKomhOUdTZrk7oOlAIiJa\n",
       "pSqpQRLPAOYAb7O5oOl4IqK/pCqpB9ncDnwYOE5i9abjiYiAlBi6gsSxwIM2H246lojoH8t670xi\n",
       "6AIST6bM3bCvzelNxxMR/SFVST3M5j7gPcD3JJ7SdDwRMdhSYugiEl8Hnmmza9OxRETvS4mhP+wP\n",
       "TJWY0XQgETG4UmLoMhIvAX4DvMjm1qbjiYjelRJDn7C5DDgM+H7mboiIJiQxdKeDgDUhj69GROel\n",
       "KqlLSWwKnAe8wubapuOJiN6TqqQ+Y/MXYCalV/SKDYcTEQMkiaG7fRu4jzISa0RER6QqqctJrAdc\n",
       "AbyhapiOiGhLV1YlSZouaa6k6yR9Zin7bSXpUUlvrzOeXlQ9svoxytwNqzYdT0T0v9oSg6QpwOHA\n",
       "dGALYIakzcfY72DgdMjjmaOx+TFlLKWvNB1LRPS/OksMWwPX277J9kLgRGCnUfb7V+CnwB01xtIP\n",
       "PgzsLPGmpgOJiP5WZ2JYD5jX8np+te5xktajJIsjqlXd3+DREJu7gZ2BH0i8pel4IqJ/1fkYZDs3\n",
       "+UOBz9q2JLGUqiRJM1tezrY9e/nC6z02F1Qlhl9JfNTmpKZjiojuIWkaMG25j1PXU0mStgFm2p5e\n",
       "vf4csMj2wS373MjiZLA28BDwftunjjjWwD6VNBqJqZQ2mc/ZHNt0PBHRnZb13llnieFSYBNJGwEL\n",
       "gF1g+KihtjceWpb0A+BXI5NCLMnmKontgTMlVrMfr4qLiFhutSUG249K2g/4LTAFONr2NZL2rbYf\n",
       "Wde5B4HNXIlXA2dVyeGrTccUEf0hHdx6nMQGwO+AHwL/ZacBPyKKbqxKig6wmVeVHM4EVpf4XJJD\n",
       "RCyPjJXUB2xupzyJsAPwDSmfa0Qsu9xA+oTNXcBrgZcA35WY0nBIEdGjkhj6iM19wOuBZ1OG616p\n",
       "4ZAiogclMfQZmweAN1NmgPuJxCoNhxQRPSaJoQ/ZPAy8jdL7/BcZlTUiJiKJoU/ZPELpVHgX8GuJ\n",
       "JzYcUkT0iCSGPmbzKLAXcANwhsSaDYcUET0giaHP2TwGfAC4BPi9xNoNhxQRXS6JYQBUHd4+Thl4\n",
       "b7bEMxsOKSK6WHo+D4gqOewv8SBwtsRr7WHzZUREAG0mhmpCnY0og+EJsO1zaowramLzZYmHgHMk\n",
       "drC5oemYIqK7jJsYJB1MebrlauCxlk1JDD3K5utVcpgt8TqbuU3HFBHdo50Sw9uAzWz/s+5gonNs\n",
       "jqySw+8l3mBzZdMxRUR3aCcx3ACsDCQx9Bmb4yX+QXmU9S02FzcdU0Q0r53E8DAwR9JZLE4Otv3R\n",
       "+sKKTrE5WeJhYJbEO2zObTqmiGjWuBP1SNq7WhzacajxuWNzDWeinvpJ7ACcAOxm87um44mI5bes\n",
       "9862ZnCTtAqwafVyru2FEz3R8khi6AyJVwA/B/axmdV0PBGxfGpLDJKmAccCN1erNgT2sn32RE+2\n",
       "rJIYOkdiK2AWsJ/NyU3HExHLrs6pPb8G7Gj72upEmwInAi+e6Mmi+9lcIvE64HSJVW2OazqmiOis\n",
       "dhLDikNJAcD2XySlx3Qfs7lKYnvgTInVbL7TdEwR0Tnt3OAvk/Q94IeUhud3A5fWGlU0zmauxDTg\n",
       "d1Vy+FrTMUVEZ7TTxvAE4CPAy6tV5wLf7mSHt7QxNEdiA+As4Djgy9WYSxHRA2p9KqlpSQzNkngG\n",
       "cCalUXr/JIeI3jDpiUHSybZ3lvSnUTbb9tSJnmxZJTE0T+KpwBnAH4FP2CxqOKSIGEcdiWFd2wsk\n",
       "bTTadts3TfRkyyqJoTtUM8CdBswFPmzzj4ZDioilWNZ755gT9dheUC3eAcyrEsEqwFTg1mUJMnqb\n",
       "zb3AjsCTgEskOlZqjIjOaWcGt3OBVao5GX4L7AEcU2dQ0b1sHgDeBRwCnCXxSSkzAUb0k3b+Q8v2\n",
       "Q8DbKU8j7Qz8v3YOLmm6pLmSrpP0mVG27yTpSklXSLpM0vYTCz+aYGObY4GXAe+gjM66XsNhRcQk\n",
       "aeubnqRtKf0Xft3u+yRNAQ4HpgNbADMkbT5it9/Z3tL2i4C9ge+2GXd0AZsbgVcDZwOXS7yz4ZAi\n",
       "YhK0kxg+DnwOOMX2nyU9B/hDG+/bGrje9k3VoHsnAju17mD7wZaXTwTubC/s6BY2j9ocCLwF+IrE\n",
       "MRJrNB1XRCy7cROD7bNtv9X2wdXrG9qci2E9GDbZ/Pxq3TCS/kXSNcBvgMzx0KOqSX5eDDwCzJEe\n",
       "7xAZET1mzCExJH3D9sck/WqUzbb91nGO3VYnKNu/AH4h6ZXA8cBmY8Qzs+XlbNuz2zl+dE7VMP0B\n",
       "iZ2An0kcBXzJpqPDtEcMqmo07GnLfZyl9GN4ie3LqhON5PGG3Za0DTDT9vTq9eeARUMljzHecwOw\n",
       "te27RqxPP4YeU/WW/j6wNrC7zV8aDili4Ez6sNu2L6sWLwUetv1YdaIpwBPaOPalwCZVB7kFwC7A\n",
       "jBFBPwe40bYlvbg6711Ez7O5XeJNwIeB8yQ+DxyV4TQiul87jc9nAau2vF6NMm7OUtl+FNiP0vfh\n",
       "auAntq+RtK+kfavd3gH8SdIVwDeAXScSfHS36rHWb1GeXPoQ8AuJpzUcVkSMo53RVefYfuF46+qU\n",
       "qqTeJ7Ey8CVgT+B9Nqc1HFJE35v0ITFaPCjpJS0neinw8ERPFIPN5hGbz1KqE4+QOFxitabjiogl\n",
       "tVNi2Ar4CaWdAOCZwC62OzZZT0oM/aUajO/bwAspDdOXNxxSRF+qdT4GSStRHiMVMLfqsNYxSQz9\n",
       "SWI34FDgq8AhNo81HFJEX6ktMUhaHfgksKHt90vaBNjM9qxlC3Xikhj6l8SzKLPDGdjT5paGQ4ro\n",
       "G3W2MfyA0pt1u+r1AuDLEz1RxGhsbga2p/R8v7QqRUREg9pJDM+pOqU9AkuMbxSx3GweszmYMuDi\n",
       "FyROqNohIqIB7SSGf0p6vB9D1Sntn/WFFIOqaoR+CXA3cKXEqxsOKWIgtZMYZgKnA+tLOgH4PbDE\n",
       "3AoRk8HmIZv9KB3ifizx31UfiIjokKU2PktaAdiZ0vt5m2r1Rbbv6EBsrXGk8XkASawDHAVsCOxm\n",
       "c03DIUX0lDqfSrrM9kuWulPNkhgGl4SA9wFfoZRev53xliLaU2di+G/KBDo/AR5veLZ990RPtqyS\n",
       "GEJiU+CHlL/FfWxubzikiK5XZ2K4iVHmVrD97ImebFklMQSAxErAF4D3Ax+0+WXDIUV0tToTw6rA\n",
       "R4BXAIuAPwJH2O7YeElJDNGqmh3ueOAi4LNVX4iIGKHODm7HAZtThsU+HNiiWhfRCJvzgBcA1wKX\n",
       "S3xZ4kkNhxXRN9opMVxte4vx1tUpJYYYi8T6wEGU3tNfAI7NmEsRRZ0lhsslbdtyom2Ay5ayf0TH\n",
       "2My32QN4G/BeyrAa05qNKqK3tVNimAtsCsyjNEJvSCnCP0qZ+3lq7UGmxBBtqB5t3Rk4GJgD/LvN\n",
       "9c1GFdGcOhufN1radts3TfSkE5XEEBMh8QTg48C/AccCB9rc22xUEZ1X63wMTUtiiGUh8QzgQOCt\n",
       "wH8C37V5tNmoIjoniSFiDBJbAl8DngF8yub0hkOK6IgkhoilqNof3gIcAtxASRBXNxtVRL3qfCop\n",
       "oufZ2OZU4P8BvwVmS3xLYu2GQ4voOkkMMVBsHrE5lNJp8zHgGolPZWjviMWSGGIg2dxl81HgVZTO\n",
       "cVdL/EtV5RQx0NLGEAFI7EhpoL4D+ITNnIZDilhuaWOIWA42ZwAvpAwvf7rE0RLPbDisiEYkMURU\n",
       "bB61+Q6wGXAX8L8Sn5dYdZy3RvSVJIaIEWzus/k0sDXwYmCuxIy0P8SgqD0xSJouaa6k6yR9ZpTt\n",
       "75Z0paSrJJ0nqfaxlyLaYXODzTuAPYF/B86XHp/7PKJv1ZoYJE2hzOEwnTKPwwxJm4/Y7UbgVdVg\n",
       "fAcC360zpoiJsjkbeClwJPAziR9JbNhwWBG1qbvEsDVwve2bbC8ETgR2at3B9gW276teXgSsX3NM\n",
       "ERNms8jmGEr7ww3AFRIHSjyx2cgiJl/diWE9ynDdQ+ZX68byXuC0WiOKWA42D9gcALwI2JjS/2Fa\n",
       "s1FFTK4Vaz5+250kJL0G2Ad4+RjbZ7a8nG179nJFFrEcbG4B3i0xHfiRxHHAATYLGw4tBpikabD8\n",
       "X1Rq7eBWzfY20/b06vXngEW2Dx6x31Tg58B020tMrJIObtHNJNYBvg+sA+yWyYGiW3RrB7dLgU0k\n",
       "bSRpZWAX4NTWHSRtSEkKu4+WFCK6nc3fKCO3HgdcIPGePNoavaz2ITEkvQE4FJgCHG37IEn7Atg+\n",
       "UtL3KPP13lK9ZaHtrUccIyWG6AkSLwBOAK4GPmhzT8MhxQDLfAwRXaLqKX0w5Qm83W3ObTikGFBJ\n",
       "DBFdRuJNwPeqny+lYTo6rVvbGCIGls2vKY+1vhQ4V2LjhkOKaEsSQ0SNbG4H3kTp3HmRxB5pmI5u\n",
       "l6qkiA6R2JLSMH0l8CGb+8Z5S8RySVVSRJezuRLYCrgXmCOxXcMhRYwqJYaIBki8lTJg5HeA/7J5\n",
       "tOGQog/lqaSIHiOxLnAssBrwbpubmo0o+k2qkiJ6jM0C4PWUnv8XS+zWcEgRQEoMEV1B4sWUhumL\n",
       "gf1s/t5wSNEHUmKI6GE2lwMvAR6mzPWQmeKiMSkxRHQZibdRGqUPAw6yeazhkKJHpfE5oo9IrAcc\n",
       "T5kzZfdq/oeICUlVUkQfsbkVeB3wa+BSiXc1HFIMkJQYIrqcxFbAj4A/Ah+1eaDhkKJHpMQQ0ads\n",
       "LgFeTJkq94oqUUTUJokhogfYPGDzXmB/YJbEZyWmNB1X9KdUJUX0GIkNgB8Ci4A9bOY3HFJ0qVQl\n",
       "RQwIm3nA9sCZwGUS72g4pOgzKTFE9DCJl1Eapv8KfAM4zWZRs1FFt0g/hogBJbEK8C7gY8CTKR3j\n",
       "jsmwGpGqpIgBZfNPm+Mpcz3sBbwcuEniGxKbNBtd9KIkhog+YWOb8212AaYCDwLnScyS2DFTika7\n",
       "UpUU0cckVgV2Az4KrESpZjrO5sFGA4uOSBtDRIypKi28mpIgXgUcAxyeyYH6W9oYImJMVTXTbJu3\n",
       "Ay+tVl8mcYrEtFQzRauUGCIGlMQTgT0opYhHgG8CJ9g83GhgMWlSlRQRy6QqLbyOkiC2Br4HfDs9\n",
       "qntfqpIiYplU1Uxn2LyZ8qjr6sBVEj+ReHmqmQZP7YlB0nRJcyVdJ+kzo2x/nqQLJP1D0qfqjici\n",
       "xmZznc3HgI2A8yiN1JdI7Fl1pIsBUGtVkqQpwLXADsCtwCXADNvXtOzzNOBZwL8A99j+6ijHSVVS\n",
       "RAMkVgDeSKlmmgocCRxhc3ujgUVburUqaWvgets32V4InAjs1LqD7TtsXwosrDmWiJggm0U2s2x2\n",
       "pAzctw5wjcTxmReif9WdGNYD5rW8nl+ti4geY3O1zYeAjYErgZMlzpfYVWKlhsOLSVR3Yuj+R54i\n",
       "YkJs7rE5BHgu8D/AB4G/Shwg8Zxmo4vJsGLNx78V2KDl9QawbI/ASZrZ8nK27dnLHlZELC+bR4FT\n",
       "gFMktgQ+AJwvcTPwY+Akm1ubjHHQSJoGTFvu49Tc+LwipfH5tcAC4GJGND637DsTuD+NzxG9S2JF\n",
       "SlvErpQHSq6itC3+1ObOJmMbRF3bwU3SG4BDgSnA0bYPkrQvgO0jJT2D8rTSGpSpCu8HtrD9QMsx\n",
       "khgiekz1eOt0YAbwBuB8SkniF5krojO6NjFMhiSGiN5WDb/xFkpJYhrwO0pJYlaG4KhPEkNE9ASJ\n",
       "tYC3UUoSWwGzKCWJM20eaTK2fpPEEBE9R+LpwM6UksTzgJ9TShJn2zzWZGz9IIkhInqaxIbALpQk\n",
       "sS5wEqUkcZGdR9+XRRJDRPQNic0oSWIG8ARKKeJE4KokifYlMURE36lGdp1KSRC7Ag9TShEn2vyl\n",
       "ydh6QRJDRPS1KklsQ0kQ76L0jRrqSHdLk7F1qySGiBgYElMoc1jPAN4OXENJEifb/K3J2LpJEkNE\n",
       "DCSJlYEdKSWJNwNnAV8Dzh/09ogkhogYeFVHur2AjwP3UBLEz+zBHNY/iSEiolJVNb0Z+ARlmPDD\n",
       "gKNs7m00sA7r1ol6IiI6zuYxm1/aTKMM5jcVuFHimxkafHxJDBHR12wut9kDeAHwAHChxCkSr6ye\n",
       "dIoRUpUUEQNFYnVgT0o1098p7RAn92M7RNoYIiImQGIF4I3AJ4FNKe0Q37W5p9HAJlHaGCIiJsBm\n",
       "kc0sm+0pDdVbADdIHC6xScPhNSqJISIGns0cm72A5wP3UqYo/aXEtEFsh0hVUkTECBKrAXtQ2iEe\n",
       "Ar4O/KTX5otIG0NExCSr2iGmU9ohNge+BRxpc1ejgbUpbQwREZOsaoc4zWYHSkP1JsD1EkdUQ4P3\n",
       "pSSGiIijBefhAAAGJ0lEQVQ22Fxp8x5KyeEO4ByJWRLb91s7RKqSIiKWgcSqwO6UdohHKO0QJ9r8\n",
       "s9HAWqSNISKiAVU7xI6UdogXUNohvg/c1vTorkkMERENk3gBZWTXtwGrAPOBeS0/w17b3FdvPEkM\n",
       "ERFdoxoCfINxfhYxPHEs8WPz0LLHkMQQEdEzqgbrJ7P0xLE+pR/FEqWNlp/5Y7VrJDFERPSZKnms\n",
       "zfBEMTJ5rEvprT1K0tCPkxgiIgZM1fj9dEYtcWjnJIaIiHhcV/Z8ljRd0lxJ10n6zBj7fLPafqWk\n",
       "F9UZT0REjK+2xCBpCnA4ZZyRLYAZkjYfsc8bgefa3gT4AHBEXfH0C0nTmo6hW+RaLJZrsViuxfKr\n",
       "s8SwNXC97ZtsLwROBHYasc9bgWMBbF8ErCnp6TXG1A+mNR1AF5nWdABdZFrTAXSRaU0H0OvqTAzr\n",
       "UVrGh8yv1o23z/o1xhQREeOoMzG026o9smGk+1vDIyL62Io1HvtWyiNTQzaglAiWts/61bolSErC\n",
       "qEj6YtMxdItci8VyLRbLtVg+dSaGS4FNJG0ELAB2AWaM2OdUYD/gREnbAPfa/r+RB8qjqhERnVNb\n",
       "YrD9qKT9gN8CU4CjbV8jad9q+5G2T5P0RknXAw8C76krnoiIaE9PdHCLiIjO6aoZ3NIhbrHxroWk\n",
       "d1fX4CpJ50ma2kScndDO30W131aSHpX09k7G1ylt/v+YJukKSf8raXaHQ+yYNv5/rC3pdElzqmux\n",
       "dwNhdoSk70v6P0l/Wso+E7tv2u6KH0p10/XARsBKwBxg8xH7vBE4rVp+GXBh03E3eC22BZ5cLU8f\n",
       "5GvRst/vgVnAO5qOu6G/iTWBPwPrV6/XbjruBq/FTOCgoesA3AWs2HTsNV2PVwIvAv40xvYJ3ze7\n",
       "qcSQDnGLjXstbF9ge2iSj4vo3/4f7fxdAPwr8FPKXLz9qJ3rsBvwM9vzAWzf2eEYO6Wda3EbsEa1\n",
       "vAZwl+1HOxhjx9g+F7hnKbtM+L7ZTYkhHeIWa+datHovcFqtETVn3GshaT3KjWFoSJV+bDhr529i\n",
       "E+Apkv4g6VJJe3Qsus5q51ocBTxf0gLgSuBjHYqtG034vlnn46oTlQ5xi7X9O0l6DbAP8PL6wmlU\n",
       "O9fiUOCzti1JLPk30g/auQ4rAS8GXgusBlwg6ULb19UaWee1cy32B+bYnibpOcCZkra0fX/NsXWr\n",
       "Cd03uykxTGqHuB7XzrWganA+Cphue2lFyV7WzrV4CaUvDJT65DdIWmj71M6E2BHtXId5wJ22HwYe\n",
       "lnQOsCXQb4mhnWuxHfBlANs3SPorsBmlf9WgmfB9s5uqkh7vECdpZUqHuJH/sU8F9gRYWoe4PjDu\n",
       "tZC0IfBzYHfb1zcQY6eMey1sb2z72bafTWln+FCfJQVo7//HL4FXSJoiaTVKQ+PVHY6zE9q5FnOB\n",
       "HQCq+vTNgBs7GmX3mPB9s2tKDE6HuMe1cy2AA4C1gCOqb8oLbW/dVMx1afNa9L02/3/MlXQ6cBVl\n",
       "kvmjbPddYmjzb+IrwA8kXUn5Avxp23c3FnSNJP0YeDWwtqR5wBcp1YrLfN9MB7eIiBimm6qSIiKi\n",
       "CyQxRETEMEkMERExTBJDREQMk8QQERHDJDFERMQwSQwRNZO0t6TDquWZkj7VdEwRS5PEEDEGVSbh\n",
       "UB5jOaIrJTFEtKiGWbhW0rHAn4AvSLq4muBkZst+e1br5lT7Iuktki6UdLmkMyWt09CvEbFcumZI\n",
       "jIgu8lxgD+DJwDttby1pBeCXkl4J3A18HtjW9t2S1qred67tbQAkvQ/4NPBv9Odor9HHkhgilnSz\n",
       "7YslHQLsKOmKav3qlKSxOnDS0Ng7LSPbbiDpJOAZwMoM7qBt0eNSlRSxpAdblg+y/aLqZ1PbP6jW\n",
       "j1YKOAz4pu2pwL7AqnUHGlGHJIaIsf0W2EfS6lBmipP0NMrc0jtLekq1fqgqaQ1gQbW89xjHTLVS\n",
       "dL1UJUUsyQC2z5S0OWUmNID7KfNfXC3py8DZkh4DLqfMojcTOFnSPZTk8ayW43mU5YiulGG3IyJi\n",
       "mFQlRUTEMEkMERExTBJDREQMk8QQERHDJDFERMQwSQwRETFMEkNERAyTxBAREcP8fx32becPNJ9M\n",
       "AAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7966f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanResult('Word Mover Distance Model', graph = True) # it takes about 2.3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_queries = [\"Two people in a group of four are holding awards as they pose for a picture.\",\\\n",
    "                \"A woman in a red dress is posing with an axe.\",\\\n",
    "                \"Two soccer plays stand next to each other with soccer balls in front of them.\"]\n",
    "test_keys = [\"CbnA_e6AW6U7Ycoa\", \"PaqtOaYmQmXkqW2i\", \"IPcFtNL-7EQ6Z0yu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testExamples(query, key):\n",
    "    best = querySimilarity(query)\n",
    "    target_doc = target_file['txt_caption'][best[0][:1000]]\n",
    "    target_key = target_file['img_id'][best[0][:1000]]\n",
    "    d = {'target':target_doc, 'match':[key]*1000 == target_key, 'score':best[1][:1000]}\n",
    "    d = pd.DataFrame(d)\n",
    "    for i in range(20):\n",
    "        print(d['match'].iloc[i])\n",
    "        print(d['score'].iloc[i])\n",
    "        print(query)\n",
    "        print(d['target'].iloc[i])\n",
    "        print()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.481899\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of people where all but two of the people are holding awards.\n",
      "\n",
      "False\n",
      "0.486348\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of seven Asian young people pose for a picture in a cafe.\n",
      "\n",
      "False\n",
      "0.542263\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Three people posing for a picture holding a trophy.\n",
      "\n",
      "False\n",
      "0.54721\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of four older people pose for a portrait.\n",
      "\n",
      "False\n",
      "0.55482\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Two men holding a trophy with a group of people applauding behind them.\n",
      "\n",
      "False\n",
      "0.561326\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Two men pose for a picture holding championship belts, who appear to be wrestlers but one's vest says \"lumberjack.\".\n",
      "\n",
      "False\n",
      "0.572742\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of three people pose for a photo dressed as pirates.\n",
      "\n",
      "False\n",
      "0.575604\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Two men in white shirts are holding a plaque in front of a group of people.\n",
      "\n",
      "False\n",
      "0.576765\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of four people are standing, two are holding silver plates.\n",
      "\n",
      "False\n",
      "0.578358\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A photo of a group of people in a gym, the room is very bright and one man in the middle of the picture is doing a pose.\n",
      "\n",
      "False\n",
      "0.583188\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A picture of three people holding a trophy in a room.\n",
      "\n",
      "False\n",
      "0.583354\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of seven workmen some holding chainsaws posing for a picture in front of a lorry.\n",
      "\n",
      "False\n",
      "0.587831\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A picture of a group of people in multiple rows holding a banner in front of them.\n",
      "\n",
      "False\n",
      "0.592154\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of five people pose for a photo while equipped with hiking gear.\n",
      "\n",
      "False\n",
      "0.598907\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Two people pose for a picture with a jacket.\n",
      "\n",
      "False\n",
      "0.602608\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of people holding a bunch of different awards.\n",
      "\n",
      "False\n",
      "0.603193\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of smartly dressed people pose for a picture around a standing clipboard.\n",
      "\n",
      "True\n",
      "0.612595\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A group of people are standing together and holding awards.\n",
      "\n",
      "False\n",
      "0.616078\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "Four children are holding hands and roller-skating in a group of people, one child is topless, they are smiling and laughing.\n",
      "\n",
      "False\n",
      "0.6181\n",
      "Two people in a group of four are holding awards as they pose for a picture.\n",
      "A picture of a group of people making peace signs to pose for the camera.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1 = testExamples(test_queries[0], test_keys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.0\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a dress and heels posing on a red carpet.\n",
      "\n",
      "False\n",
      "0.0\n",
      "A woman in a red dress is posing with an axe.\n",
      "A young woman in a tan dress posing for a picture at the red carpet.\n",
      "\n",
      "False\n",
      "0.0\n",
      "A woman in a red dress is posing with an axe.\n",
      "A red haired woman in a dress is posing.\n",
      "\n",
      "False\n",
      "0.0\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman with red hair in a brown dress posing in front of a curtain.\n",
      "\n",
      "False\n",
      "0.0\n",
      "A woman in a red dress is posing with an axe.\n",
      "A picture of a woman in a red dress posing for the camera.\n",
      "\n",
      "False\n",
      "9.76563e-05\n",
      "A woman in a red dress is posing with an axe.\n",
      "A smiling, tanned brunette woman wearing a sleeveless dress, and gladiator sandals, and holding a clutch, stands posing on the red carpet for the camera, with one hand on her hip.\n",
      "\n",
      "False\n",
      "9.76563e-05\n",
      "A woman in a red dress is posing with an axe.\n",
      "A skinny woman in a red dress posing for a picture in front of a movie poster.\n",
      "\n",
      "False\n",
      "0.141573\n",
      "A woman in a red dress is posing with an axe.\n",
      "A young girl in a black dress and black shoes posing with a hand on her hip, on a red carpet, against a screen backdrop.\n",
      "\n",
      "False\n",
      "0.154368\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman posing in a red gown.\n",
      "\n",
      "False\n",
      "0.166326\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a red dress poses for a picture.\n",
      "\n",
      "False\n",
      "0.166424\n",
      "A woman in a red dress is posing with an axe.\n",
      "A young woman wearing a shiny red dress poses on the red carpet.\n",
      "\n",
      "False\n",
      "0.166424\n",
      "A woman in a red dress is posing with an axe.\n",
      "A dark curly-haired woman with red lipstick and a silver bracelet poses in a short black dress.\n",
      "\n",
      "False\n",
      "0.166424\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a long dress poses on a red carpet in front of a charity poster.\n",
      "\n",
      "False\n",
      "0.167878\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a wedding dress posing in front of a purple back ground.\n",
      "\n",
      "False\n",
      "0.17699\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman wearing a pink dress is posing.\n",
      "\n",
      "False\n",
      "0.17699\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman posing in a pink dress.\n",
      "\n",
      "False\n",
      "0.17699\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a pink dress posing for the photo.\n",
      "\n",
      "False\n",
      "0.177088\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman wearing a pink dress posing in a mirror whilst looking at the camera.\n",
      "\n",
      "False\n",
      "0.18106\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman wearing a black top and jeans, pulls a funny face whilst posing on the red carpet, and pointing her finger at the camera man.\n",
      "\n",
      "False\n",
      "0.183383\n",
      "A woman in a red dress is posing with an axe.\n",
      "A woman in a long cream colored dress is posing for the camera.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test2 = testExamples(test_queries[1], test_keys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.289566\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two soccer players in orange and black striped t-shirts, stand waiting in front of some balls.\n",
      "\n",
      "True\n",
      "0.570836\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men are standing with soccer balls.\n",
      "\n",
      "False\n",
      "0.678701\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men play soccer inside.\n",
      "\n",
      "False\n",
      "0.683275\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two opposing soccer players going for the ball.\n",
      "\n",
      "False\n",
      "0.688384\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two opposing teammates trying to get control of the soccer ball during a game.\n",
      "\n",
      "False\n",
      "0.712177\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two soccer players battle for the ball.\n",
      "\n",
      "False\n",
      "0.733084\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two girls stand in plaid shirts and flip flops in front of blue lockers.\n",
      "\n",
      "False\n",
      "0.737305\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men stand in front of a wall with their wrestling belts.\n",
      "\n",
      "False\n",
      "0.741593\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two people playing a game of soccer.\n",
      "\n",
      "False\n",
      "0.742253\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men from opposing teams playing soccer.\n",
      "\n",
      "False\n",
      "0.743452\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men play basketball in front of a crowd.\n",
      "\n",
      "False\n",
      "0.747688\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two girls in matching checked shirts strike the same pose as they stand in front of blue lockers.\n",
      "\n",
      "False\n",
      "0.750251\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two young women in bikinis stand either side of a man in shorts next to a truck.\n",
      "\n",
      "False\n",
      "0.761178\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Three soccer players on a field playing while one is up in the air.\n",
      "\n",
      "False\n",
      "0.761523\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two woman with scarves covering their heads standing next to a rake in front of a structure.\n",
      "\n",
      "False\n",
      "0.764957\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two soccer players clash during a game.\n",
      "\n",
      "True\n",
      "0.769778\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two soccer players in orange and black uniforms with orange socks on the field.\n",
      "\n",
      "False\n",
      "0.77133\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two apprehensive men, one with a camera, stand in front of a graffiti covered wall.\n",
      "\n",
      "False\n",
      "0.773219\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men in front of a microphone with a sign that has a bird on it next to them.\n",
      "\n",
      "False\n",
      "0.773808\n",
      "Two soccer plays stand next to each other with soccer balls in front of them.\n",
      "Two men in navy blue shirts stand in front of a table with a blue tablecloth, behind which are a man and a woman who are looking at a piece of paper on the table.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test3 = testExamples(test_queries[2], test_keys[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
